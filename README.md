# DataMAx - Pharmaceutical Data Analytics Platform

A multi-cloud pharmaceutical data analytics platform for processing, analyzing, and visualizing clinical trial and drug data.

## ğŸš€ Project Overview

DataMAx is a full-stack data analytics platform built to demonstrate enterprise-scale data engineering and backend development capabilities. The platform processes pharmaceutical data, provides RESTful APIs for data access, and includes a web interface for data visualization.

## ğŸ—ï¸ Architecture

### Tech Stack
- **Backend**: Python 3.10+, FastAPI, SQLAlchemy
- **Database**: PostgreSQL
- **Frontend**: Angular 16+
- **Data Processing**: Pandas, NumPy
- **Testing**: pytest, unittest
- **Containerization**: Docker, Docker Compose
- **Cloud**: AWS/Azure compatible architecture

### Components
1. **Backend API** (`/backend`) - RESTful services for data operations
2. **Data Pipeline** (`/data-pipeline`) - ETL workflows for pharmaceutical data
3. **Database** (`/database`) - Schema, migrations, and SQL scripts
4. **Frontend** (`/frontend`) - Angular dashboard for data visualization
5. **Tests** (`/tests`) - Unit and integration tests

## ğŸ“‹ Features

- âœ… RESTful API for pharmaceutical data operations
- âœ… Data ingestion and processing pipelines
- âœ… Data quality validation and monitoring
- âœ… SQL-based data analytics and reporting
- âœ… Interactive data visualization dashboard
- âœ… Containerized deployment with Docker
- âœ… Comprehensive unit test coverage

## ğŸ”§ Prerequisites

- Python 3.10 or higher
- Node.js 16+ and npm
- PostgreSQL 13+
- Docker and Docker Compose (optional)

## ğŸš€ Quick Start

### Using Docker (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd Axtria

# Start all services
docker-compose up -d

# Access the application
# Frontend: http://localhost:4200
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### Manual Setup

#### 1. Database Setup

```bash
# Start PostgreSQL
sudo systemctl start postgresql

# Create database
psql -U postgres
CREATE DATABASE datamax;
\q

# Run migrations
cd database
psql -U postgres -d datamax -f schema.sql
psql -U postgres -d datamax -f seed_data.sql
```

#### 2. Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your database credentials

# Run the backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### 3. Frontend Setup

```bash
cd frontend
npm install
ng serve
```

#### 4. Data Pipeline

```bash
cd data-pipeline
pip install -r requirements.txt
python pipeline/main.py --mode full
```

## ğŸ“Š API Documentation

Once the backend is running, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Key Endpoints

- `GET /api/v1/drugs` - List all drugs
- `GET /api/v1/clinical-trials` - List clinical trials
- `POST /api/v1/data/ingest` - Ingest new data
- `GET /api/v1/analytics/summary` - Get analytics summary
- `GET /api/v1/health` - Health check

## ğŸ§ª Running Tests

```bash
# Backend tests
cd backend
pytest tests/ -v --cov=app

# Integration tests
pytest tests/integration/ -v

# Data pipeline tests
cd data-pipeline
pytest tests/ -v
```

## ğŸ“ Project Structure

```
Axtria/
â”œâ”€â”€ backend/                    # FastAPI backend service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”‚   â”œâ”€â”€ schemas/           # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”œâ”€â”€ db/                # Database connection
â”‚   â”‚   â””â”€â”€ main.py            # Application entry point
â”‚   â”œâ”€â”€ tests/                 # Backend tests
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data-pipeline/             # Data processing workflows
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ extractors/        # Data extraction
â”‚   â”‚   â”œâ”€â”€ transformers/      # Data transformation
â”‚   â”‚   â”œâ”€â”€ loaders/           # Data loading
â”‚   â”‚   â””â”€â”€ validators/        # Data quality checks
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ database/                  # Database scripts
â”‚   â”œâ”€â”€ schema.sql            # Table definitions
â”‚   â”œâ”€â”€ migrations/           # Database migrations
â”‚   â”œâ”€â”€ queries/              # Common SQL queries
â”‚   â””â”€â”€ seed_data.sql         # Sample data
â”œâ”€â”€ frontend/                  # Angular frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ services/     # API services
â”‚   â”‚   â”‚   â””â”€â”€ models/       # TypeScript models
â”‚   â”‚   â””â”€â”€ assets/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker/                    # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ Dockerfile.pipeline
â”œâ”€â”€ docs/                      # Additional documentation
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ” Environment Variables

Create a `.env` file in the backend directory:

```env
DATABASE_URL=postgresql://postgres:password@localhost:5432/datamax
SECRET_KEY=your-secret-key-here
ENVIRONMENT=development
LOG_LEVEL=INFO
```

## ğŸ“ˆ Data Pipeline Workflow

1. **Extract** - Fetch data from various sources (CSV, APIs, databases)
2. **Transform** - Clean, validate, and enrich pharmaceutical data
3. **Load** - Insert processed data into PostgreSQL
4. **Validate** - Run quality checks and generate reports


## ğŸ“ Key Skills Demonstrated

- âœ… Python OOP, data structures, and algorithms
- âœ… RESTful API design and development
- âœ… SQL and relational database management
- âœ… Data pipeline development
- âœ… Frontend development (Angular)
- âœ… Version control with Git
- âœ… Docker containerization
- âœ… Unit testing with pytest
- âœ… Cloud-native architecture

